https://www.kaggle.com/models/google/resnet-v2/tensorFlow2/50-feature-vector/2?tfhub-redirect=true

Use this model maybe??

Look at these code classifier.py and Dogs_vs_Wolves_ResNet50.ipynb files and understand..
I want you to create a new py file just like these files, with all the same outputs that I would see if I ran the py.
I tried to build but it wasn't so good. Some of the below points are there in the wsi code, but they don't work.. like the otsu.. and the direct streaming to the model is so slow.
But, make the this better, this is another application.
Add a random seed for reproducibility. Make the loss graphs look better or something if possible. Also, in this, make it such that it takes these folders
from dataset for training: "adeno" and "squamous". These contain .svs files from whole slide images, so add a step to convert each slide image into patches, 
and get one prediction per slide. i.e, Combine patch predictions to get a slide-level result. Also, take the patches in different resolutions/zoom. Get it?
Basically, extract and classify patches, then aggregate the results for the whole slide.

Also:
ignore this - try to reduce memory/disk usage by streaming patches instead of saving to disk. - save everything to disk as jpg or png patches or whatever.
Add an example cell that visualizes a few extracted patches per slide.
Tissue masking (Otsu or thresholding) to skip empty/background patches didn't really work that well. many blank patches also were taken for training/testing.
So I'm thinking, after all patches are saved to a folder, then what if I manually delete the patches that are blank, and then the program continues the training and testing with only the patches that are now available in the folder?? 
Add patch-level saliency visualization (Grad-CAM) to highlight predictive regions.
Convert the inference loop to save slide-level predictions and a CSV summary of slide probabilities..

I also had a few doubts from the output of my old model. I had given 20 adeno and 20 squamous slides as input.
And these are few snippets of the output:
Dataset split:
  Training slides: 32, patches: 1703
  Testing slides: 8, patches: 374
Found 40 slides
  Adeno: 20
  Squamous: 20
  
How is the distribution of adeno and squamous in the 8 slides that it has taken for testing?
And is it like, every epoch, the 8 slides are random/different?
Also, the number of patches from each slide may differ. How is this combated?

My old code also gave this in output:

Also, after all this I will be using the generated model to predict on a full folder with svs images. tell how to do that also. For that also, I need an output csv file..
with these columns:
Slide Name,Predicted Class,Confidence,Patch Agreement,Num Patches,Adeno Prob,Squamous Prob